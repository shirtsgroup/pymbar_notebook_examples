{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "Example illustrating the application of MBAR to compute a 1D free energy profile <br>\n", "from a series of force-clamp single-molecule experiments.<br>\n", "REFERENCE<br>\n", "    Woodside MT, Behnke-Parks WL, Larizadeh K, Travers K, Herschlag D, and Block SM.<br>\n", "    Nanomechanical measurements of the sequence-dependent folding landscapes of single<br>\n", "    nucleic acid hairpins. PNAS 103:6190, 2006.<br>\n", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["=============================================================================================<br>\n", "IMPORTS<br>\n", "============================================================================================="]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import subprocess\n", "import time\n", "from pathlib import Path"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import matplotlib"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["matplotlib.use(\"Agg\")\n", "import matplotlib.pyplot as plt"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pymbar  # multistate Bennett acceptance ratio analysis (provided by pymbar)\n", "from pymbar import timeseries, FES  # timeseries analysis (provided by pymbar)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["=============================================================================================<br>\n", "PARAMETERS<br>\n", "============================================================================================="]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["prefix = \"20R55_4T\"  # for paper\n", "# prefix = '10R50_4T'\n", "# prefix = '25R50_4T'\n", "# prefix = '30R50_4T'\n", "directory = Path(\"processed-data\")\n", "temperature = 296.15  # temperature (in K)\n", "nbins = 50  # number of bins for 1D FES\n", "output_directory = Path(\"output\")\n", "plot_directory = Path(\"plots\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["=============================================================================================<br>\n", "CONSTANTS<br>\n", "============================================================================================="]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["kB = 1.381e-23  # Boltzmann constant (in J/K)\n", "pN_nm_to_kT = (1.0e-9) * (1.0e-12) / (kB * temperature)  # conversion from nM pN to units of kT"]}, {"cell_type": "markdown", "metadata": {}, "source": ["=============================================================================================<br>\n", "SUBROUTINES<br>\n", "============================================================================================="]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def construct_nonuniform_bins(x_n, nbins):\n", "    \"\"\"Construct histogram using bins of unequal size to ensure approximately equal population in each bin.\n", "    Parameters\n", "    ----------\n", "    x_n : 1D array of float\n", "        x_n[n] is data point n\n", "    Returns\n", "    -------\n", "    bin_left_boundary_i : 1D array of floats\n", "        data in bin i will satisfy bin_left_boundary_i[i] <= x < bin_left_boundary_i[i+1]\n", "    bin_center_i : 1D array of floats\n", "        bin_center_i[i] is the center of bin i\n", "    bin_width_i : 1D array of floats\n", "        bin_width_i[i] is the width of bin i\n", "    bin_n : 1D array of int32\n", "        bin_n[n] is the bin index (in range(nbins)) of x_n[n]\n", "    \"\"\"\n\n", "    # Determine number of samples.\n", "    N = x_n.size\n\n", "    # Get indices of elements of x_n sorted in order.\n", "    sorted_indices = x_n.argsort()\n\n", "    # Allocate storage for results.\n", "    bin_left_boundary_i = np.zeros([nbins + 1])\n", "    bin_center_i = np.zeros([nbins])\n", "    bin_width_i = np.zeros([nbins])\n", "    bin_n = np.zeros([N])\n\n", "    # Determine sampled range, adding a little bit to the rightmost range to ensure no samples escape the range.\n", "    x_min = x_n.min()\n", "    x_max = x_n.max()\n", "    x_max += (x_max - x_min) * 1.0e-5\n\n", "    # Determine bin boundaries and bin assignments.\n", "    for bin_index in range(nbins):\n", "        # indices of first and last data points in this span\n", "        first_index = int(float(N) / float(nbins) * float(bin_index))\n", "        last_index = int(float(N) / float(nbins) * float(bin_index + 1))\n\n", "        # store left bin boundary\n", "        bin_left_boundary_i[bin_index] = x_n[sorted_indices[first_index]]\n\n", "        # store assignments\n", "        bin_n[sorted_indices[first_index:last_index]] = bin_index\n\n", "    # set rightmost boundary\n", "    bin_left_boundary_i[nbins] = x_max\n\n", "    # Determine bin centers and widths\n", "    for bin_index in range(nbins):\n", "        bin_center_i[bin_index] = (\n", "            bin_left_boundary_i[bin_index] + bin_left_boundary_i[bin_index + 1]\n", "        ) / 2.0\n", "        bin_width_i[bin_index] = (\n", "            bin_left_boundary_i[bin_index + 1] - bin_left_boundary_i[bin_index]\n", "        )\n", "    return bin_left_boundary_i, bin_center_i, bin_width_i, bin_n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["=============================================================================================<br>\n", "MAIN<br>\n", "============================================================================================="]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def main():\n", "    # read biasing forces for different trajectories\n", "    filename = directory / f\"{prefix}.forces\"\n", "    with open(filename) as infile:\n", "        elements = infile.readline().split()\n", "        K = len(elements)  # number of biasing forces\n", "        # biasing_force_k[k] is the constant external biasing force used to collect trajectory k (in pN)\n", "        biasing_force_k = np.zeros([K])\n", "        for k in range(K):\n", "            biasing_force_k[k] = float(elements[k])\n", "    print(\"biasing forces (in pN) = \", biasing_force_k)\n\n", "    # Determine maximum number of snapshots in all trajectories.\n", "    filename = directory / f\"{prefix}.trajectories\"\n", "    T_max = 0\n", "    with open(filename) as f:\n", "        for line in f:\n", "            T_max += 1\n\n", "    # Allocate storage for original (correlated) trajectories\n", "    T_k = np.zeros([K], int)  # T_k[k] is the number of snapshots from umbrella simulation k`\n", "    # x_kt[k,t] is the position of snapshot t from trajectory k (in nm)\n", "    x_kt = np.zeros([K, T_max])\n\n", "    # Read the trajectories.\n", "    filename = directory / f\"{prefix}.trajectories\"\n", "    print(f\"Reading {filename}...\")\n", "    with open(filename) as infile:\n", "        for line in infile:\n", "            elements = line.split()\n", "            for k in range(K):\n", "                t = T_k[k]\n", "                x_kt[k, t] = float(elements[k])\n", "                T_k[k] += 1\n\n", "    # Create a list of indices of all configurations in kt-indexing.\n", "    mask_kt = np.zeros([K, T_max], dtype=bool)\n", "    for k in range(K):\n", "        mask_kt[k, 0 : T_k[k]] = True\n", "    # Create a list from this mask.\n", "    all_data_indices = np.where(mask_kt)\n\n", "    # Construct equal-frequency extension bins\n", "    print(\"binning data...\")\n", "    bin_kt = np.zeros([K, T_max], int)\n", "    bin_left_boundary_i, bin_center_i, bin_width_i, bin_assignments = construct_nonuniform_bins(\n", "        x_kt[all_data_indices], nbins\n", "    )\n", "    bin_kt[all_data_indices] = bin_assignments\n\n", "    # Compute correlation times.\n", "    N_max = 0\n", "    g_k = np.zeros([K])\n", "    for k in range(K):\n", "        # Compute statistical inefficiency for extension timeseries\n", "        g = timeseries.statistical_inefficiency(x_kt[k, 0 : T_k[k]], x_kt[k, 0 : T_k[k]])\n", "        # store statistical inefficiency\n", "        g_k[k] = g\n", "        print(\n", "            f\"timeseries {k + 1:d} : g = {g:.1f}, {int(np.floor(T_k[k] / g)):.0f} \"\n", "            f\"uncorrelated samples (of {T_k[k]:d} total samples)\"\n", "        )\n", "        N_max = max(N_max, int(np.ceil(T_k[k] / g)) + 1)\n\n", "    # Subsample trajectory position data.\n", "    x_kn = np.zeros([K, N_max])\n", "    bin_kn = np.zeros([K, N_max])\n", "    N_k = np.zeros([K], int)\n", "    for k in range(K):\n", "        # Compute correlation times for potential energy and chi timeseries.\n", "        indices = timeseries.subsample_correlated_data(x_kt[k, 0 : T_k[k]])\n", "        # Store subsampled positions.\n", "        N_k[k] = len(indices)\n", "        x_kn[k, 0 : N_k[k]] = x_kt[k, indices]\n", "        bin_kn[k, 0 : N_k[k]] = bin_kt[k, indices]\n\n", "    # Set arbitrarynp.zeros for external biasing potential.\n", "    x0_k = np.zeros([K])  # x position corresponding to zero of potential\n", "    for k in range(K):\n", "        x0_k[k] = x_kn[k, 0 : N_k[k]].mean()\n", "    print(\"x0_k = \", x0_k)\n\n", "    # Compute bias energies in units of kT.\n", "    # u_kln[k,l,n] is the reduced (dimensionless) relative potential energy of\n", "    # snapshot n from umbrella simulation k evaluated at umbrella l\n", "    u_kln = np.zeros([K, K, N_max])\n", "    for k in range(K):\n", "        for l in range(K):\n", "            # compute relative energy difference from sampled state to each other state\n", "            # U_k(x) = F_k x\n", "            # where F_k is external biasing force\n", "            # (F_k pN) (x nm) (pN /\n", "            # u_kln[k,l,0:N_k[k]] = - pN_nm_to_kT * (biasing_force_k[l] - biasing_force_k[k]) * x_kn[k,0:N_k[k]]\n", "            u_kln[k, l, 0 : N_k[k]] = -pN_nm_to_kT * biasing_force_k[l] * (\n", "                x_kn[k, 0 : N_k[k]] - x0_k[l]\n", "            ) + pN_nm_to_kT * biasing_force_k[k] * (x_kn[k, 0 : N_k[k]] - x0_k[k])\n\n", "    # DEBUG\n", "    start_time = time.time()\n\n", "    # Initialize MBAR.\n", "    print(\"Running MBAR...\")\n", "    # TODO: change to u_kn inputs\n", "    mbar = pymbar.MBAR(\n", "        u_kln, N_k, verbose=True, relative_tolerance=1.0e-10, solver_protocol=\"robust\"\n", "    )\n\n", "    # Compute unbiased energies (all biasing forces are zero).\n", "    # u_n[n] is the reduced potential energy without umbrella restraints of snapshot n\n", "    u_n = np.zeros([np.sum(N_k)])\n", "    x_n = np.zeros([np.sum(N_k)])\n", "    Nstart = 0\n", "    for k in range(K):\n", "        #    u_n[N_k[k]:N_k[k+1]] = - pN_nm_to_kT * (0.0 - biasing_force_k[k]) * x_kn[k,0:N_k[k]]\n", "        u_n[Nstart : Nstart + N_k[k]] = 0.0 + pN_nm_to_kT * biasing_force_k[k] * (\n", "            x_kn[k, 0 : N_k[k]] - x0_k[k]\n", "        )\n", "        x_n[Nstart : Nstart + N_k[k]] = x_kn[k, 0 : N_k[k]]\n", "        Nstart += N_k[k]\n\n", "    # Compute free energy profile in unbiased potential (in units of kT).\n", "    print(\"Computing free energy profile...\")\n", "    fes = FES(u_kln, N_k, mbar_options=dict(solver_protocol=\"robust\"))\n", "    histogram_parameters = dict()\n", "    # 1D array of parameters, one entry because 1D\n", "    histogram_parameters[\"bin_edges\"] = bin_left_boundary_i\n", "    fes.generate_fes(u_n, x_n, histogram_parameters=histogram_parameters)\n", "    results = fes.get_fes(\n", "        bin_center_i, reference_point=\"from-lowest\", uncertainty_method=\"analytical\"\n", "    )\n", "    f_i = results[\"f_i\"]\n", "    df_i = results[\"df_i\"]\n\n", "    # compute estimate of FES including Jacobian term\n", "    fes_i = f_i + np.log(bin_width_i)\n", "    # Write out unbiased estimate of FES\n", "    print(\"Unbiased FES (in units of kT)\")\n", "    print(f\"{'bin':>8s} {'f':>8s} {'df':>8s} {'fes':>8s} {'width':>8s}\")\n", "    for i in range(nbins):\n", "        print(\n", "            f\"{bin_center_i[i]:8.3f}\",\n", "            f\"{f_i[i]:8.3f}\",\n", "            f\"{df_i[i]:8.3f}\",\n", "            f\"{fes_i[i]:8.3f}\",\n", "            f\"{bin_width_i[i]:8.3f}\",\n", "        )\n", "    filename = output_directory / \"fes-unbiased.out\"\n", "    with open(filename, \"w\") as outfile:\n", "        for i in range(nbins):\n", "            outfile.write(f\"{bin_center_i[i]:8.3f} {fes_i[i]:8.3f} {df_i[i]:8.3f}\\n\")\n", "    fig_filename = plot_directory / f\"fes-unbiased.pdf\"\n", "    fig, ax = plt.subplots()\n", "    ax.errorbar(bin_center_i, fes_i, yerr=df_i, fmt=\"_ \", elinewidth=0.3)\n", "    ax.set_title(\"Unbiased estimate of free energy profile\")\n", "    ax.set_ylabel(\"Free energy profile of mean force (kT)\")\n", "    ax.set_xlabel(\"Extension (nm)\")\n", "    fig.savefig(fig_filename)\n\n", "    # DEBUG\n", "    stop_time = time.time()\n", "    elapsed_time = stop_time - start_time\n", "    print(f\"analysis took {elapsed_time:f} seconds\")\n\n", "    # compute observed and expected histograms at each state\n", "    for l in range(K):\n", "        # compute FES at state l\n", "        Nstart = 0\n", "        for k in range(K):\n", "            u_n[Nstart : Nstart + N_k[k]] = u_kln[k, l, 0 : N_k[k]]\n", "            Nstart += N_k[k]\n", "        fes.generate_fes(u_n, x_n, histogram_parameters=histogram_parameters)\n", "        results = fes.get_fes(\n", "            bin_center_i, reference_point=\"from-lowest\", uncertainty_method=\"analytical\"\n", "        )\n", "        f_i = results[\"f_i\"]\n", "        df_i = results[\"df_i\"]\n\n", "        # compute estimate of FES including Jacobian term\n", "        fes_i = f_i + np.log(bin_width_i)\n", "        # center fes\n", "        fes_i -= fes_i.mean()\n", "        # compute probability distribution\n", "        p_i = np.exp(-f_i + f_i.min())\n", "        p_i /= p_i.sum()\n", "        # compute observed histograms, filtering to within [x_min,x_max] range\n", "        N_i_observed = np.zeros([nbins])\n", "        dN_i_observed = np.zeros([nbins])\n", "        for t in range(T_k[l]):\n", "            bin_index = bin_kt[l, t]\n", "            N_i_observed[bin_index] += 1\n", "        N = N_i_observed.sum()\n", "        # estimate uncertainties in observed counts\n", "        for bin_index in range(nbins):\n", "            dN_i_observed[bin_index] = np.sqrt(\n", "                g_k[l] * N_i_observed[bin_index] * (1.0 - N_i_observed[bin_index] / float(N))\n", "            )\n", "        # compute expected histograms\n", "        N_i_expected = float(N) * p_i\n", "        # only approximate, since correlations df_i df_j are neglected\n", "        dN_i_expected = np.sqrt(float(N) * p_i * (1.0 - p_i))\n", "        # plot\n", "        print(f\"state {l:d} ({biasing_force_k[l]:f} pN)\")\n", "        for bin_index in range(nbins):\n", "            print(\n", "                f\"{bin_center_i[bin_index]:8.3f}\",\n", "                f\"{N_i_expected[bin_index]:10f}\",\n", "                f\"{N_i_observed[bin_index]:10f} +- {dN_i_observed[bin_index]:10f}\",\n", "            )\n\n", "        # Write out observed bin counts\n", "        filename = output_directory / f\"counts-observed-{l:d}.out\"\n", "        with open(filename, \"w\") as outfile:\n", "            for i in range(nbins):\n", "                outfile.write(\n", "                    f\"{bin_center_i[i]:8.3f} {N_i_observed[i]:16f} {dN_i_observed[i]:16f}\\n\"\n", "                )\n\n", "        # write out expected bin counts\n", "        filename = output_directory / f\"counts-expected-{l:d}.out\"\n", "        with open(filename, \"w\") as outfile:\n", "            for i in range(nbins):\n", "                outfile.write(\n", "                    f\"{bin_center_i[i]:8.3f} {N_i_expected[i]:16f} {dN_i_expected[i]:16f}\\n\"\n", "                )\n\n", "        # compute FES from observed counts\n", "        indices = np.where(N_i_observed > 0)[0]\n", "        fes_i_observed = np.zeros([nbins])\n", "        dfes_i_observed = np.zeros([nbins])\n", "        fes_i_observed[indices] = -np.log(N_i_observed[indices]) + np.log(bin_width_i[indices])\n", "        fes_i_observed[indices] -= fes_i_observed[indices].mean()  # shift observed FES\n", "        dfes_i_observed[indices] = dN_i_observed[indices] / N_i_observed[indices]\n", "        # write out observed FES\n", "        filename = output_directory / f\"fes-observed-{l:d}.out\"\n", "        with open(filename, \"w\") as outfile:\n", "            for i in indices:\n", "                outfile.write(\n", "                    f\"{bin_center_i[i]:8.3f} {fes_i_observed[i]:8.3f} {dfes_i_observed[i]:8.3f}\\n\"\n", "                )\n\n", "        # Write out unbiased estimate of FES\n", "        fes_i -= fes_i[indices].mean()  # shift to align with observed\n", "        filename = output_directory / f\"fes-expected-{l:d}.out\"\n", "        with open(filename, \"w\") as outfile:\n", "            for i in range(nbins):\n", "                outfile.write(f\"{bin_center_i[i]:8.3f} {fes_i[i]:8.3f} {df_i[i]:8.3f}\\n\")\n\n", "        # make plots\n", "        biasing_force = biasing_force_k[l]\n", "        fig_filename = plot_directory / f\"fes-comparison-{l:d}.pdf\"\n", "        fig, ax = plt.subplots()\n", "        ax.errorbar(\n", "            bin_center_i, fes_i, yerr=df_i, fmt=\"x \", elinewidth=0.3, label=\"MBAR optimal estimate\"\n", "        )\n", "        ax.errorbar(\n", "            bin_center_i,\n", "            fes_i_observed,\n", "            yerr=dfes_i_observed,\n", "            fmt=\"x \",\n", "            elinewidth=0.3,\n", "            label=\"Observed from single experiment\",\n", "        )\n", "        ax.set_title(f\"{prefix.title()} - {biasing_force:.2f} pN\")\n", "        ax.set_ylabel(\"Free energy of profile (kT)\")\n", "        ax.set_xlabel(\"Extension (nm)\")\n", "        ax.legend()\n", "        fig.savefig(fig_filename)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == \"__main__\":\n", "    main()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}