{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#!/usr/bin/python"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "Estimate 2D free energy surface for alanine dipeptide parallel tempering data using MBAR.<br>\n", "PROTOCOL<br>\n", "* Potential energies and (phi, psi) torsions from parallel tempering simulation are read in by temperature<br>\n", "* Replica trajectories of potential energies and torsions are reconstructed to reflect their true temporal<br>\n", "  correlation, and then subsampled to produce statistically independent samples, collecting them again by temperature<br>\n", "* The `pymbar` class is initialized to compute the dimensionless free energies at each temperature using MBAR<br>\n", "* The torsions are binned into sequentially labeled bins in two dimensions<br>\n", "* The relative free energies and uncertainties of these torsion bins at the temperature of interest is estimated<br>\n", "* The 2D free energy surface is written out<br>\n", "REFERENCES<br>\n", "[1] Shirts MR and Chodera JD. Statistically optimal analysis of samples from multiple equilibrium states.<br>\n", "J. Chem. Phys. 129:124105, 2008. http://dx.doi.org/10.1063/1.2978177<br>\n", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["===================================================================================================<br>\n", "IMPORTS<br>\n", "==================================================================================================="]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from pathlib import Path"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import pymbar  # for MBAR analysis"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from pymbar import timeseries  # for timeseries analysis"]}, {"cell_type": "markdown", "metadata": {}, "source": ["===================================================================================================<br>\n", "CONSTANTS<br>\n", "==================================================================================================="]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["kB = 1.3806503 * 6.0221415 / 4184.0  # Boltzmann constant in kcal/mol/K"]}, {"cell_type": "markdown", "metadata": {}, "source": ["===================================================================================================<br>\n", "PARAMETERS<br>\n", "==================================================================================================="]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["DATA_DIRECTORY = Path(\"data/\")  # directory containing the parallel tempering data\n", "# file containing temperatures in K\n", "temperature_list_filename = DATA_DIRECTORY / \"temperatures\"\n", "free_energies_filename = \"f_k.out\"\n", "# file containing total energies (in kcal/mol) for each temperature and snapshot\n", "potential_energies_filename = DATA_DIRECTORY / \"energies\" / \"potential-energies\"\n", "trajectory_segment_length = 20  # number of snapshots in each contiguous trajectory segment\n", "niterations = 500  # number of iterations to use\n", "target_temperature = 302  # target temperature for 2D free energy surface (in K)\n", "nbins_per_torsion = 10  # number of bins per torsion dimension"]}, {"cell_type": "markdown", "metadata": {}, "source": ["===================================================================================================<br>\n", "SUBROUTINES<br>\n", "==================================================================================================="]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def read_file(filename):\n", "    \"\"\"Read contents of the specified file.\n", "    Parameters:\n", "    -----------\n", "    filename : str\n", "        The name of the file to be read\n", "    Returns\n", "    -------\n", "    lines : list of str\n", "        The contents of the file, split by line\n", "    \"\"\"\n", "    with open(filename, \"r\") as f:\n", "        return f.readlines()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["===================================================================================================<br>\n", "MAIN<br>\n", "==================================================================================================="]}, {"cell_type": "markdown", "metadata": {}, "source": ["===================================================================================================<br>\n", "Read temperatures<br>\n", "==================================================================================================="]}, {"cell_type": "markdown", "metadata": {}, "source": ["Read list of temperatures."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["lines = read_file(temperature_list_filename)\n", "# Construct list of temperatures\n", "temperatures = lines[0].split()\n", "# Create array of temperatures\n", "K = len(temperatures)\n", "temperature_k = np.zeros([K])  # temperature_k[k] is temperature of temperature index k in K\n", "for k in range(K):\n", "    temperature_k[k] = float(temperatures[k])\n", "# Compute inverse temperatures\n", "beta_k = (kB * temperature_k) ** (-1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Define other constants"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["T = trajectory_segment_length * niterations  # total number of snapshots per temperature"]}, {"cell_type": "markdown", "metadata": {}, "source": ["===================================================================================================<br>\n", "Read potential eneriges<br>\n", "==================================================================================================="]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"Reading potential energies...\")\n", "# U_kn[k,t] is the potential energy (in kcal/mol) for snapshot t of temperature index k\n", "U_kt = np.zeros([K, T])\n", "lines = read_file(potential_energies_filename)\n", "print(f\"{len(lines):d} lines read, processing {T:d} snapshots\")\n", "for t in range(T):\n", "    # Get line containing the energies for snapshot t of trajectory segment n\n", "    line = lines[t]\n", "    # Extract energy values from text\n", "    elements = line.split()\n", "    for k in range(K):\n", "        U_kt[k, t] = float(elements[k])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["===================================================================================================<br>\n", "Read phi, psi trajectories<br>\n", "==================================================================================================="]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"Reading phi, psi trajectories...\")\n", "# phi_kt[k,n,t] is phi angle (in degrees) for snapshot t of temperature k\n", "phi_kt = np.zeros([K, T])\n", "# psi_kt[k,n,t] is psi angle (in degrees) for snapshot t of temperature k\n", "psi_kt = np.zeros([K, T])\n", "for k in range(K):\n", "    phi_filename = DATA_DIRECTORY / \"backbone-torsions\" / f\"{k:d}.phi\"\n", "    psi_filename = DATA_DIRECTORY / \"backbone-torsions\" / f\"{k:d}.psi\"\n", "    phi_lines = read_file(phi_filename)\n", "    psi_lines = read_file(psi_filename)\n", "    print(f\"k = {k:d}, {len(phi_lines):d} phi lines read, {len(psi_lines):d} psi lines read\")\n", "    for t in range(T):\n", "        # Extract phi and psi\n", "        phi_kt[k, t] = float(phi_lines[t])\n", "        psi_kt[k, t] = float(psi_lines[t])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["===================================================================================================<br>\n", "Read replica indices<br>\n", "==================================================================================================="]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"Reading replica indices...\")\n", "filename = DATA_DIRECTORY / \"replica-indices\"\n", "lines = read_file(filename)\n", "# replica_ki[i,k] is the replica index of temperature k for iteration i\n", "replica_ik = np.zeros([niterations, K], np.int32)\n", "for i in range(niterations):\n", "    elements = lines[i].split()\n", "    for k in range(K):\n", "        replica_ik[i, k] = int(elements[k])\n", "print(f\"Replica indices for {niterations:d} iterations processed.\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["===================================================================================================<br>\n", "Permute data by replica and subsample to generate an uncorrelated subset of data by temperature<br>\n", "==================================================================================================="]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["assume_uncorrelated = False\n", "if assume_uncorrelated:\n", "    # DEBUG - use all data, assuming it is uncorrelated\n", "    print(\"Using all data, assuming it is uncorrelated...\")\n", "    U_kn = U_kt.copy()\n", "    phi_kn = phi_kt.copy()\n", "    psi_kn = psi_kt.copy()\n", "    N_k = np.zeros([K], np.int32)\n", "    N_k[:] = T\n", "    N_max = T\n", "else:\n", "    # Permute data by replica\n", "    print(\"Permuting data by replica...\")\n", "    U_kt_replica = U_kt.copy()\n", "    phi_kt_replica = psi_kt.copy()\n", "    psi_kt_replica = psi_kt.copy()\n", "    for iteration in range(niterations):\n", "        # Determine which snapshot indices are associated with this iteration\n", "        snapshot_indices = iteration * trajectory_segment_length + np.arange(\n", "            0, trajectory_segment_length\n", "        )\n", "        for k in range(K):\n", "            # Determine which replica generated the data from temperature k at this iteration\n", "            replica_index = replica_ik[iteration, k]\n", "            # Reconstruct portion of replica trajectory.\n", "            U_kt_replica[replica_index, snapshot_indices] = U_kt[k, snapshot_indices]\n", "            phi_kt_replica[replica_index, snapshot_indices] = phi_kt[k, snapshot_indices]\n", "            psi_kt_replica[replica_index, snapshot_indices] = psi_kt[k, snapshot_indices]\n", "    # Estimate the statistical inefficiency of the simulation by analyzing the timeseries of interest.\n", "    # We use the max of cos and sin of the phi and psi timeseries because they are periodic angles.\n", "    # The  ## TODO: ???\n", "    print(\"Computing statistical inefficiencies...\")\n", "    g_cosphi = timeseries.statistical_inefficiency_multiple(np.cos(phi_kt_replica * np.pi / 180.0))\n", "    print(f\"g_cos(phi) = {g_cosphi:.1f}\")\n", "    g_sinphi = timeseries.statistical_inefficiency_multiple(np.sin(phi_kt_replica * np.pi / 180.0))\n", "    print(f\"g_sin(phi) = {g_sinphi:.1f}\")\n", "    g_cospsi = timeseries.statistical_inefficiency_multiple(np.cos(psi_kt_replica * np.pi / 180.0))\n", "    print(f\"g_cos(psi) = {g_cospsi:.1f}\")\n", "    g_sinpsi = timeseries.statistical_inefficiency_multiple(np.sin(psi_kt_replica * np.pi / 180.0))\n", "    print(f\"g_sin(psi) = {g_sinpsi:.1f}\")\n", "    # Subsample data with maximum of all correlation times.\n", "    print(\"Subsampling data...\")\n", "    g = np.max(np.array([g_cosphi, g_sinphi, g_cospsi, g_sinpsi]))\n", "    indices = timeseries.subsample_correlated_data(U_kt[k, :], g=g)\n", "    print(f\"Using g = {g:.1f} to obtain {len(indices):d} uncorrelated samples per temperature\")\n", "    N_max = int(np.ceil(T / g))  # max number of samples per temperature\n", "    U_kn = np.zeros([K, N_max])\n", "    phi_kn = np.zeros([K, N_max])\n", "    psi_kn = np.zeros([K, N_max])\n", "    N_k = N_max * np.ones([K], dtype=int)\n", "    for k in range(K):\n", "        U_kn[k, :] = U_kt[k, indices]\n", "        phi_kn[k, :] = phi_kt[k, indices]\n", "        psi_kn[k, :] = psi_kt[k, indices]\n", "    print(f\"{N_max:d} uncorrelated samples per temperature\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["===================================================================================================<br>\n", "Generate a list of indices of all configurations in kn-indexing<br>\n", "==================================================================================================="]}, {"cell_type": "markdown", "metadata": {}, "source": ["Create a list of indices of all configurations in kn-indexing."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["mask_kn = np.zeros([K, N_max], dtype=bool)\n", "for k in range(K):\n", "    mask_kn[k, 0 : N_k[k]] = True\n", "# Create a list from this mask.\n", "indices = np.where(mask_kn)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["===================================================================================================<br>\n", "Compute reduced potential energy of all snapshots at all temperatures<br>\n", "==================================================================================================="]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"Computing reduced potential energies...\")\n", "# u_kln[k,l,n] is reduced potential energy of trajectory segment n of temperature k evaluated at temperature l\n", "u_kln = np.zeros([K, K, N_max])\n", "for k in range(K):\n", "    for l in range(K):\n", "        u_kln[k, l, 0 : N_k[k]] = beta_k[l] * U_kn[k, 0 : N_k[k]]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["===================================================================================================<br>\n", "Bin torsions into histogram bins for free energy surface calculation<br>\n", "==================================================================================================="]}, {"cell_type": "markdown", "metadata": {}, "source": ["Here, we bin the (phi,psi) samples into bins in a 2D histogram.<br>\n", "We assign indices 0...(nbins-1) to the bins, even though the histograms are in two dimensions.<br>\n", "All bins must have at least one sample in them.<br>\n", "This strategy scales to an arbitrary number of dimensions."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"Binning torsions...\")\n", "# Determine torsion bin size (in degrees)\n", "torsion_min = -180.0\n", "torsion_max = +180.0\n", "dx = (torsion_max - torsion_min) / float(nbins_per_torsion)\n", "# Assign torsion bins\n", "# bin_kn[k,n] is the index of which histogram bin sample n from temperature index k belongs to\n", "bin_kn = np.zeros([K, N_max], dtype=int)\n", "nbins = 0\n", "bin_nonzero = 0\n", "bin_counts = []\n", "bin_centers = []  # bin_centers[i] is a (phi,psi) tuple that gives the center of bin i\n", "count_nonzero = []\n", "centers_nonzero = []"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for i in range(nbins_per_torsion):\n", "    for j in range(nbins_per_torsion):\n", "        # Determine (phi,psi) of bin center.\n", "        phi = torsion_min + dx * (i + 0.5)\n", "        psi = torsion_min + dx * (j + 0.5)\n\n", "        # Determine which configurations lie in this bin.\n", "        in_bin = (\n", "            (phi - dx / 2 <= phi_kn[indices])\n", "            & (phi_kn[indices] < phi + dx / 2)\n", "            & (psi - dx / 2 <= psi_kn[indices])\n", "            & (psi_kn[indices] < psi + dx / 2)\n", "        )\n", "        # Count number of configurations in this bin.\n", "        bin_count = in_bin.sum()\n", "        # Generate list of indices in bin.\n", "        # set bin indices of both dimensions\n", "        if bin_count > 0:\n", "            count_nonzero.append(bin_count)\n", "            centers_nonzero.append((phi, psi))\n", "            bin_nonzero += 1"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(f\"{bin_nonzero:d} bins were populated:\")\n", "for i in range(bin_nonzero):\n", "    print(\n", "        f\"bin {i:5d} ({centers_nonzero[i][0]:6.1f}, {centers_nonzero[i][1]:6.1f}) {count_nonzero[i]:12d} conformations\"\n", "    )"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["x_n = np.zeros([np.sum(N_k), 2])  # the configurations"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Ntot = 0\n", "for k in range(K):\n", "    for n in range(N_k[k]):\n", "        x_n[Ntot, 0] = phi_kn[k, n]\n", "        x_n[Ntot, 1] = psi_kn[k, n]\n", "        Ntot += 1"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["bin_edges = []\n", "for i in range(2):\n", "    bin_edges.append(np.linspace(torsion_min, torsion_max, nbins_per_torsion + 1))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Initialize free energy surface with data collected"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fes = pymbar.FES(u_kln, N_k, mbar_options=dict(solver_protocol=\"robust\"))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["===================================================================================================<br>\n", "Compute free energy surface at the desired temperature.<br>\n", "==================================================================================================="]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"Computing free energy surface...\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Compute reduced potential energies at the temperaure of interest"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["target_beta = 1.0 / (kB * target_temperature)\n", "u_kn = target_beta * U_kn\n", "# Compute FES at this temperature, returning dimensionless free energies and uncertainties.\n", "# f_i[i] is the dimensionless free energy of bin i (in kT) at the temperature of interest\n", "# df_i[i,j] is an estimate of the covariance in the estimate of (f_i[i] - f_j[j], with reference\n", "# the lowest free energy state.\n", "# Compute FES in unbiased potential (in units of kT).\n", "histogram_parameters = {}\n", "histogram_parameters[\"bin_edges\"] = bin_edges\n", "fes.generate_fes(u_kn, x_n, fes_type=\"histogram\", histogram_parameters=histogram_parameters)\n", "results = fes.get_fes(\n", "    np.array(centers_nonzero), reference_point=\"from-lowest\", uncertainty_method=\"analytical\"\n", ")\n", "f_i = results[\"f_i\"]\n", "df_i = results[\"df_i\"]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Show free energy and uncertainty of each occupied bin relative to lowest free energy"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"2D free energy surface\")\n", "print()\n", "print(f\"{'bin':>8s} {'phi':>6s} {'psi':>6s} {'N':>8s} {'f':>10s} {'df':>10s}\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for i in range(bin_nonzero):\n", "    print(\n", "        f\"{i:>8d} {centers_nonzero[i][0]:>6.1f} {centers_nonzero[i][1]:>6.1f} {count_nonzero[i]:>8d} {f_i[i]:>10.3f} {df_i[i]:>10.3f}\"\n", "    )"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}