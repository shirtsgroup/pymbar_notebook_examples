{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "Example illustrating the application of MBAR to compute a 1D free energy profile from an umbrella sampling simulation.<br>\n",
    "The data represents an umbrella sampling simulation for the chi torsion of a valine sidechain in lysozyme L99A with benzene bound in the cavity.<br>\n",
    "Reference:<br>\n",
    "    [1] M. R. Shirts and Andrew L. Ferguson,<br>\n",
    "    \"Statistically optimal continuous potentials of mean force from<br>\n",
    "    umbrella sampling and multistate reweighting\" https://arxiv.org/abs/2001.01170<br>\n",
    "    [2] D. L. Mobley, A. P. Graves, J. D. Chodera, A. C. McReynolds, B. K. Shoichet and K. A. Dill,<br>\n",
    "    \"Predicting absolute ligand binding free energies to a simple model site,\"<br>\n",
    "    Journal of Molecular Biology 371(4):1118-1134 (2007).<br>\n",
    "    http://dx.doi.org/10.1016/j.jmb.2007.06.002<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from timeit import default_timer as timer\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np  # numerical array library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymbar  # multistate Bennett acceptance ratio\n",
    "from pymbar import timeseries  # timeseries analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kB = 1.381e-23 * 6.022e23 / 1000.0  # Boltzmann constant in kJ/mol/K\n",
    "nplot = 1200\n",
    "# set minimizer options to display.\n",
    "optimize_options = {\"disp\": True, \"tol\": 10 ** (-8)}\n",
    "# histogram is self explanatory.  'kde' is a kernel density approximation. Currently it uses a\n",
    "# Gaussian kernel, but this can be adjusted in the kde_parameters section below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\"histogram\", \"kde\", \"unbiased-ml\", \"unbiased-map\"]\n",
    "mc_methods = [\"unbiased-map\"]  # which methods to run MCMC sampling on (much slower).\n",
    "# The code supports arbitrary powers of of B-splines (that are supported by scipy\n",
    "# Just replace '3' with the desired degree below. 1-5 suggested.\n",
    "spline_degree = 3\n",
    "nspline = 11  # number of spline knots used for the fit.\n",
    "n_bootstraps = 3  # should increase to ~50 for good statistics\n",
    "mc_iterations = 1000  # could take a while?\n",
    "smoothness_scalefac = 0.01\n",
    "fig_suffix = \"test1\"  # figure suffix for identifiability of the output!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {}\n",
    "descriptions = {}\n",
    "colors[\"histogram\"] = \"k-\"\n",
    "colors[\"kde\"] = \"k:\"\n",
    "colors[\"biased-ml\"] = \"g-\"\n",
    "colors[\"biased-map\"] = \"g--\"\n",
    "colors[\"unbiased-ml\"] = \"b-\"\n",
    "colors[\"unbiased-map\"] = \"b--\"\n",
    "descriptions[\"histogram\"] = \"Histogram\"\n",
    "descriptions[\"kde\"] = \"Kernel density (Gaussian)\"\n",
    "descriptions[\"unbiased-ml\"] = \"Unbiased state maximum likelihood\"\n",
    "descriptions[\"unbiased-map\"] = \"Unbiased state maximum a posteriori\"\n",
    "descriptions[\"simple\"] = \"vFEP\"\n",
    "descriptions[\"biased-ml\"] = \"biased states maximum likelihood\"\n",
    "descriptions[\"biased-map\"] = \"biased states maximum a posteriori\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization_algorithm = \"Newton-CG\"  # other good options are 'L-BFGS-B' and 'Custom-NR'\n",
    "# optimization_algorithm = 'Custom-NR'  #other good options are 'L-BFGS-B' and 'Custom-NR'\n",
    "# below - information to load the data.\n",
    "temperature = 300  # assume a single temperature -- can be overridden with data from center.dat\n",
    "# Parameters\n",
    "K = 26  # number of umbrellas\n",
    "N_max = 501  # maximum number of snapshots/simulation\n",
    "T_k = np.ones(K, float) * temperature  # inital temperatures are all equal\n",
    "beta = 1.0 / (kB * temperature)  # inverse temperature of simulations (in 1/(kJ/mol))\n",
    "chi_min = -180.0  # min for free energy profile\n",
    "chi_max = +180.0  # max for free energy profile\n",
    "# number of bins for 1D free energy profile. Note, does not have to correspond to the number of umbrellas at all.\n",
    "nbins = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allocate storage for simulation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_k = np.zeros([K], np.int32)  # N_k[k] is the number of snapshots from umbrella simulation k\n",
    "# K_k[k] is the spring constant (in kJ/mol/deg**2) for umbrella simulation k\n",
    "K_k = np.zeros([K], np.float64)\n",
    "# chi0_k[k] is the spring center location (in deg) for umbrella simulation k\n",
    "chi0_k = np.zeros([K], np.float64)\n",
    "# chi_kn[k,n] is the torsion angle (in deg) for snapshot n from umbrella simulation k\n",
    "chi_kn = np.zeros([K, N_max], np.float64)\n",
    "# u_kn[k,n] is the reduced potential energy without umbrella restraints of snapshot n of umbrella simulation k\n",
    "u_kn = np.zeros([K, N_max], np.float64)\n",
    "g_k = np.zeros([K], np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in umbrella spring constants and centers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/centers.dat\") as infile:\n",
    "    lines = infile.readlines()\n",
    "for k in range(K):\n",
    "    # Parse line k.\n",
    "    line = lines[k]\n",
    "    tokens = line.split()\n",
    "    chi0_k[k] = float(tokens[0])  # spring center locatiomn (in deg)\n",
    "    # spring constant (read in kJ/mol/rad**2, converted to kJ/mol/deg**2)\n",
    "    K_k[k] = float(tokens[1]) * (np.pi / 180) ** 2\n",
    "    if len(tokens) > 2:\n",
    "        T_k[k] = float(tokens[2])  # temperature the kth simulation was run at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_k = 1.0 / (kB * T_k)  # beta factor for the different temperatures\n",
    "different_temperatures = True\n",
    "if min(T_k) == max(T_k):\n",
    "    # if all the temperatures are the same, then we don't have to read in energies.\n",
    "    different_temperatures = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the simulation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(K):\n",
    "    # Read torsion angle data.\n",
    "    filename = f\"data/prod{k:d}_dihed.xvg\"\n",
    "    print(f\"Reading {filename}...\")\n",
    "    with open(filename) as infile:\n",
    "        lines = infile.readlines()\n",
    "\n",
    "    # Parse data.\n",
    "    n = 0\n",
    "    for line in lines:\n",
    "        if line[0] != \"#\" and line[0] != \"@\":\n",
    "            tokens = line.split()\n",
    "            chi = float(tokens[1])  # torsion angle\n",
    "            # wrap chi_kn to be within [-180,+180)\n",
    "            while chi < -180.0:\n",
    "                chi += 360.0\n",
    "            while chi >= +180.0:\n",
    "                chi -= 360.0\n",
    "            chi_kn[k, n] = chi\n",
    "            n += 1\n",
    "    N_k[k] = n\n",
    "    if different_temperatures:  # if different temperatures are specified the metadata file,\n",
    "        # then we need the energies to compute the free energy profile\n",
    "        # Read energies\n",
    "        filename = f\"data/prod{k:d}_energies.xvg\"\n",
    "        print(f\"Reading {filename}...\")\n",
    "        with open(filename) as infile:\n",
    "            lines = infile.readlines()\n",
    "\n",
    "        # Parse data.\n",
    "        n = 0\n",
    "        for line in lines:\n",
    "            if line[0] != \"#\" and line[0] != \"@\":\n",
    "                tokens = line.split()\n",
    "                # reduced potential energy without umbrella restraint\n",
    "                u_kn[k, n] = beta_k[k] * (float(tokens[2]) - float(tokens[1]))\n",
    "                n += 1\n",
    "\n",
    "    # Compute correlation times for potential energy and chi\n",
    "    # timeseries.  If the temperatures differ, use energies to determine samples; otherwise, use the cosine of chi\n",
    "    if different_temperatures:\n",
    "        g_k[k] = timeseries.statistical_inefficiency(u_kn[k, :], u_kn[k, 0 : N_k[k]])\n",
    "        print(f\"Correlation time for set {k:5d} is {g_k[k]:10.3f}\")\n",
    "        indices = timeseries.subsample_correlated_data(u_kn[k, 0 : N_k[k]])\n",
    "    else:\n",
    "        chi_radians = chi_kn[k, 0 : N_k[k]] / (180.0 / np.pi)\n",
    "        g_cos = timeseries.statistical_inefficiency(np.cos(chi_radians))\n",
    "        g_sin = timeseries.statistical_inefficiency(np.sin(chi_radians))\n",
    "        print(f\"g_cos = {g_cos:.1f} | g_sin = {g_sin:.1f}\")\n",
    "        # g_k[k] = max(g_cos, g_sin)  #TODO: switch?\n",
    "        g_k[k] = 1\n",
    "        print(f\"Correlation time for set {k:5d} is {g_k[k]:10.3f}\")\n",
    "        indices = timeseries.subsample_correlated_data(chi_radians, g=g_k[k])\n",
    "    # Subsample data.\n",
    "    N_k[k] = len(indices)\n",
    "    u_kn[k, 0 : N_k[k]] = u_kn[k, indices]\n",
    "    chi_kn[k, 0 : N_k[k]] = chi_kn[k, indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_max = np.max(N_k)  # shorten the array size\n",
    "# u_kln[k,l,n] is the reduced potential energy of snapshot n from umbrella simulation k evaluated at umbrella l\n",
    "u_kln = np.zeros([K, K, N_max], np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set zero of u_kn -- this is arbitrary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_kn -= u_kn.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct torsion bins<br>\n",
    "compute bin centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_center_i = np.zeros([nbins], np.float64)\n",
    "bin_edges = np.linspace(chi_min, chi_max, nbins + 1)\n",
    "for i in range(nbins):\n",
    "    bin_center_i[i] = 0.5 * (bin_edges[i] + bin_edges[i + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = np.sum(N_k)\n",
    "chi_n = pymbar.utils.kn_to_n(chi_kn, N_k=N_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate reduced energies in all umbrellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluating reduced potential energies...\")\n",
    "for k in range(K):\n",
    "    for n in range(N_k[k]):\n",
    "        # Compute minimum-image torsion deviation from umbrella center l\n",
    "        dchi = chi_kn[k, n] - chi0_k\n",
    "        for l in range(K):\n",
    "            if abs(dchi[l]) > 180.0:\n",
    "                dchi[l] = 360.0 - abs(dchi[l])\n",
    "\n",
    "        # Compute energy of snapshot n from simulation k in umbrella potential l\n",
    "        u_kln[k, :, n] = u_kn[k, n] + beta_k[k] * (K_k / 2.0) * dchi**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initialize free energy profile with the data collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basefes = pymbar.FES(u_kln, N_k, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias_potential(x, k):\n",
    "    \"\"\"Define the bias potentials needed for umbrella sampling\"\"\"\n",
    "    dchi = x - chi0_k[k]\n",
    "    # vectorize the conditional\n",
    "    i = np.fabs(dchi) > 180.0\n",
    "    dchi = i * (360.0 - np.fabs(dchi)) + (1 - i) * dchi\n",
    "    return beta_k[k] * (K_k[k] / 2.0) * dchi**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deltag(c, scalef=1, n=nspline):\n",
    "    \"\"\"bias on the smoothness, including periodicity. Normalization is indepednent of parameters, so we ignore.\n",
    "    consider periodicity later!!\n",
    "    \"\"\"\n",
    "    cdiff = np.diff(c)\n",
    "    logp = -scalef / n * (np.sum(cdiff**2))\n",
    "    return logp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddeltag(c, scalef=1, n=nspline):\n",
    "    r\"\"\"derivative of the log prior above\n",
    "    The logprior is \\sum_{i}^{C-1} - scalef*(c_{i+1} - c_{i})^2\n",
    "    this is unnormalized.  However, the normalization is independent of the values of the parameters, it only\n",
    "    depends on the hyperparameter a, so we can omit it in the normalization.\n",
    "    However, we fix c[1] to be zero.  So we are actually minimizing -scalef (c1)^2 + \\sum_{i=1}^{C-1} - scalef*(c_{i+1} - c_{i})^2\n",
    "    So the derivative is  -2*scalef*[c[1]-c[2],c[1]+2*c[2]-c[3],c[2]+2*c[3]-c[4], . . ., c[C-1]-c[C]]\n",
    "    Finally, for the minimization, we are the first coefficient to zero, and it's not allowed to move.\n",
    "    so we shift everything over by\n",
    "    \"\"\"\n",
    "    cdiff = np.diff(c)\n",
    "    lenc = len(c)\n",
    "    dlogp = np.zeros(lenc)\n",
    "    dlogp[0 : lenc - 1] = cdiff\n",
    "    dlogp[1:lenc] -= cdiff\n",
    "    # c[0] only occurs in the first two entries. We ignore the 0th (no derivative) and in the second, it's: 2a*(c[0]-2c[1]+c[2]), so\n",
    "    # settting it zero is equal to ignoring it.\n",
    "    dlogp = (2 * scalef / n) * dlogp\n",
    "    return dlogp[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dddeltag(c, scalef=1, n=nspline):\n",
    "    r\"\"\"\n",
    "    Hessian of the log prior above\n",
    "    The logprior is \\sum_{i}^{C-1} - scalef*(c_{i+1} - c_{i})^2\n",
    "    this is unnormalized.  However, the normalization is independent of the values of the parameters, it only\n",
    "    depends on the hyperparameter a, so we can omit it in the normalization\n",
    "    The derivative is -2*scalef*[c[1]-c[2],c[1]+2*c[2]-c[3],c[2]+2*c[3]-c[4], . . ., c[C-1]-c[C]]\n",
    "    so the hessian willl be a constant matrix.  Will have -2 down diagonal, 1 on off diagonal, except for\n",
    "    first and last rows\n",
    "    \"\"\"\n",
    "    cdiff = np.diff(c)\n",
    "    lenc = len(c)\n",
    "    ddlogp = np.zeros([lenc, lenc])\n",
    "    np.fill_diagonal(ddlogp, -2.0)\n",
    "    np.fill_diagonal(ddlogp[1:], 1.0)\n",
    "    np.fill_diagonal(ddlogp[:, 1:], 1.0)\n",
    "    ddlogp[0, 0] = -1\n",
    "    ddlogp[lenc - 1, lenc - 1] = -1\n",
    "    ddlogp = (2 * scalef / n) * ddlogp\n",
    "    # the first variable is set to zero in the MAP.\n",
    "    return ddlogp[1:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = {}  # keep track of time elaped each method takes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xplot = np.linspace(chi_min, chi_max, nplot)  # number of points we are plotting\n",
    "f_i_kde = None  # We check later if these have been defined or not\n",
    "# the data we used initially to parameterize points, from the KDE\n",
    "xstart = np.linspace(chi_min, chi_max, nbins * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feses = {}\n",
    "for methodfull in methods:\n",
    "    # create a fresh copy of the initialized fes object. Operate on that within the loop.\n",
    "    # do the deepcopy here since there seem to be issues if it's done after data is added\n",
    "    # For example, the scikit-learn kde object fails to deepopy.\n",
    "    feses[methodfull] = copy.deepcopy(basefes)\n",
    "    fes = feses[methodfull]\n",
    "    start = timer()\n",
    "    if \"-\" in methodfull:\n",
    "        method, tominimize = methodfull.split(\"-\")\n",
    "    else:\n",
    "        method = methodfull\n",
    "    if method == \"histogram\":\n",
    "        histogram_parameters = {}\n",
    "        histogram_parameters[\"bin_edges\"] = bin_edges\n",
    "        fes.generate_fes(\n",
    "            u_kn,\n",
    "            chi_n,\n",
    "            fes_type=\"histogram\",\n",
    "            histogram_parameters=histogram_parameters,\n",
    "            n_bootstraps=n_bootstraps,\n",
    "        )\n",
    "    if method == \"kde\":\n",
    "        kde_parameters = {}\n",
    "        # set the sigma for the spline.\n",
    "        kde_parameters[\"bandwidth\"] = 0.5 * ((chi_max - chi_min) / nbins)\n",
    "        fes.generate_fes(\n",
    "            u_kn, chi_n, fes_type=\"kde\", kde_parameters=kde_parameters, n_bootstraps=n_bootstraps\n",
    "        )\n",
    "\n",
    "        # save this for initializing other types\n",
    "        results = fes.get_fes(xstart, reference_point=\"from-lowest\", uncertainty_method=None)\n",
    "        f_i_kde = results[\"f_i\"]  # kde results\n",
    "    if method in [\"unbiased\", \"biased\", \"simple\"]:\n",
    "        spline_parameters = {}\n",
    "        if method == \"unbiased\":\n",
    "            spline_parameters[\"spline_weights\"] = \"unbiasedstate\"\n",
    "        elif method == \"biased\":\n",
    "            spline_parameters[\"spline_weights\"] = \"biasedstates\"\n",
    "        elif method == \"simple\":\n",
    "            spline_parameters[\"spline_weights\"] = \"simplesum\"\n",
    "        spline_parameters[\"nspline\"] = nspline\n",
    "        spline_parameters[\"spline_initialize\"] = \"explicit\"\n",
    "\n",
    "        # need to initialize: use KDE results for now (assumes KDE exists)\n",
    "        spline_parameters[\"xinit\"] = xstart\n",
    "        if f_i_kde is not None:\n",
    "            spline_parameters[\"yinit\"] = f_i_kde\n",
    "        else:\n",
    "            spline_parameters[\"yinit\"] = np.zeros(len(xstart))\n",
    "        spline_parameters[\"xrange\"] = [chi_min, chi_max]\n",
    "        # introduce klocal to force K to use local definition of K, otherwise would use global value of k.\n",
    "        spline_parameters[\"fkbias\"] = [\n",
    "            (lambda x, klocal=k: bias_potential(x, klocal)) for k in range(K)\n",
    "        ]\n",
    "        spline_parameters[\"kdegree\"] = spline_degree\n",
    "        spline_parameters[\"optimization_algorithm\"] = optimization_algorithm\n",
    "        spline_parameters[\"optimize_options\"] = optimize_options\n",
    "        if tominimize == \"map\":\n",
    "            spline_parameters[\"objective\"] = \"map\"\n",
    "            spline_parameters[\"map_data\"] = {}\n",
    "            spline_parameters[\"map_data\"][\"logprior\"] = lambda x: deltag(\n",
    "                x, scalef=smoothness_scalefac\n",
    "            )\n",
    "            spline_parameters[\"map_data\"][\"dlogprior\"] = lambda x: ddeltag(\n",
    "                x, scalef=smoothness_scalefac\n",
    "            )\n",
    "            spline_parameters[\"map_data\"][\"ddlogprior\"] = lambda x: dddeltag(\n",
    "                x, scalef=smoothness_scalefac\n",
    "            )\n",
    "        else:\n",
    "            spline_parameters[\"objective\"] = \"ml\"\n",
    "            spline_parameters[\"map_data\"] = None\n",
    "        fes.generate_fes(\n",
    "            u_kn,\n",
    "            chi_n,\n",
    "            fes_type=\"spline\",\n",
    "            spline_parameters=spline_parameters,\n",
    "            n_bootstraps=n_bootstraps,\n",
    "        )\n",
    "    end = timer()\n",
    "    times[methodfull] = end - start\n",
    "    yout = {}\n",
    "    yerr = {}\n",
    "    print(f\"free energy profile (in units of kT) for {methodfull}\")\n",
    "    print(f\"{'bin':>8s} {'f':>8s} {'df':>8s}\")\n",
    "    if method == \"histogram\":\n",
    "        uncertainty_method = \"analytical\"\n",
    "    else:\n",
    "        uncertainty_method = \"bootstrap\"\n",
    "    results = fes.get_fes(\n",
    "        bin_center_i, reference_point=\"from-lowest\", uncertainty_method=uncertainty_method\n",
    "    )\n",
    "    for i in range(nbins):\n",
    "        if \"df_i\" in results and results[\"df_i\"] is not None:\n",
    "            print(f\"{bin_center_i[i]:8.1f} {results['f_i'][i]:8.1f} {results['df_i'][i]:8.1f}\")\n",
    "        else:\n",
    "            print(f\"{bin_center_i[i]:8.1f} {results['f_i'][i]:8.1f}\")\n",
    "    results = fes.get_fes(\n",
    "        xplot, reference_point=\"from-lowest\", uncertainty_method=uncertainty_method\n",
    "    )\n",
    "    yout[methodfull] = results[\"f_i\"]\n",
    "    yerr[methodfull] = results[\"df_i\"]\n",
    "    if len(xplot) <= nbins:\n",
    "        errorevery = 1\n",
    "    else:\n",
    "        errorevery = int(np.floor(len(xplot) / nbins))\n",
    "    if method == \"histogram\":\n",
    "        # handle histogram differently\n",
    "        perbin = nplot // nbins\n",
    "        # get the errors in the rigtt place\n",
    "        indices = np.arange(0, nplot, perbin) + int(perbin // 2)\n",
    "        plt.errorbar(\n",
    "            xplot[indices],\n",
    "            yout[method][indices],\n",
    "            yerr=yerr[method][indices],\n",
    "            fmt=\"none\",\n",
    "            ecolor=\"k\",\n",
    "            elinewidth=1.0,\n",
    "            capsize=3,\n",
    "        )\n",
    "        plt.plot(xplot, yout[method], colors[method], label=descriptions[method])\n",
    "    else:\n",
    "        plt.errorbar(\n",
    "            xplot,\n",
    "            yout[methodfull],\n",
    "            yerr=yerr[methodfull],\n",
    "            errorevery=errorevery,\n",
    "            label=descriptions[methodfull],\n",
    "            fmt=colors[methodfull],\n",
    "            elinewidth=0.8,\n",
    "            capsize=3,\n",
    "        )\n",
    "        if \"-ml\" in methodfull:\n",
    "            aic = fes.get_information_criteria(type=\"AIC\")\n",
    "            bic = fes.get_information_criteria(type=\"BIC\")\n",
    "            print(f\"AIC for {method} with {nspline:d} splines is: {aic:f}\")\n",
    "            print(f\"BIC for {method} with {nspline:d} splines is: {bic:f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlim([chi_min, chi_max])\n",
    "plt.ylim([0, 20])\n",
    "plt.xlabel(\"Torsion angle (degrees)\")\n",
    "plt.ylabel(r\"free energy profile (units of $k_BT$)\")\n",
    "plt.legend(fontsize=\"x-small\")\n",
    "plt.title(\"Comparison of free energy profiles\")\n",
    "plt.savefig(f\"compare_fes_{fig_suffix}.pdf\")\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now perform MC sampling in parameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pltname = [\n",
    "    \"bayes_posterior_histogram\",\n",
    "    \"bayesian_95percent\",\n",
    "    \"bayesian_1sigma\",\n",
    "    \"parameter_time_series\",\n",
    "]\n",
    "for method in mc_methods:\n",
    "    fes = feses[method]\n",
    "    mc_parameters = {\n",
    "        \"niterations\": mc_iterations,\n",
    "        \"fraction_change\": 0.05,\n",
    "        \"sample_every\": 10,\n",
    "        \"logprior\": lambda x: deltag(x, scalef=smoothness_scalefac),\n",
    "        \"print_every\": 50,\n",
    "    }\n",
    "    fes.sample_parameter_distribution(chi_n, mc_parameters=mc_parameters, decorrelate=True)\n",
    "    mc_results = fes.get_mc_data()\n",
    "    plt.figure(1)\n",
    "    plt.hist(mc_results[\"logposteriors\"], label=descriptions[method])\n",
    "\n",
    "    # plot maximum likelihood as well\n",
    "    method_ml = method.replace(\"map\", \"ml\")\n",
    "    fes_ml = feses[method_ml]\n",
    "    results_ml = fes_ml.get_fes(xplot, reference_point=\"from-lowest\", uncertainty_method=None)\n",
    "    plt.figure(2)\n",
    "    plt.xlim([chi_min, chi_max])\n",
    "    ci_results = fes.get_confidence_intervals(xplot, 2.5, 97.5, reference=\"zero\")\n",
    "    ylow = ci_results[\"plow\"]\n",
    "    yhigh = ci_results[\"phigh\"]\n",
    "    plt.plot(xplot, ci_results[\"values\"], colors[method], label=descriptions[method])\n",
    "    plt.plot(xplot, results_ml[\"f_i\"], colors[method_ml], label=descriptions[method_ml])\n",
    "    plt.fill_between(xplot, ylow, yhigh, color=colors[method][0], alpha=0.3)\n",
    "    plt.title(\"FES with 95% confidence intervals\")\n",
    "    plt.xlabel(\"Torsion angle (degrees)\")\n",
    "    plt.ylabel(r\"free energy profile (units of $k_BT$)\")\n",
    "    plt.figure(3)\n",
    "    plt.xlim([chi_min, chi_max])\n",
    "    ci_results = fes.get_confidence_intervals(xplot, 16, 84)\n",
    "    plt.plot(xplot, ci_results[\"values\"], colors[method], label=descriptions[method])\n",
    "    plt.plot(xplot, results_ml[\"f_i\"], colors[method_ml], label=descriptions[method_ml])\n",
    "    ylow = ci_results[\"plow\"]\n",
    "    yhigh = ci_results[\"phigh\"]\n",
    "    plt.fill_between(xplot, ylow, yhigh, color=colors[method][0], alpha=0.3)\n",
    "    plt.xlabel(\"Torsion angle (degrees)\")\n",
    "    plt.ylabel(r\"free energy profile (units of $k_BT$)\")\n",
    "    plt.title(\"free energy profile (in units of kT) with 1 sigma percent confidence intervals\")\n",
    "\n",
    "    # plot the timeseries of the parameters to check for equilibration\n",
    "    plt.figure(4)\n",
    "    samples = mc_results[\"samples\"]\n",
    "    lp, lt = np.shape(samples)\n",
    "    for p in range(lp):\n",
    "        plt.plot(np.arange(lt), samples[p, :], label=f\"{p:d}_{method}\")\n",
    "    plt.title(\"Spline parameter time series\")\n",
    "\n",
    "    # print text results\n",
    "    ci_results = fes.get_confidence_intervals(bin_center_i, 16, 84)\n",
    "    df = (ci_results[\"phigh\"] - ci_results[\"plow\"]) / 2\n",
    "    print(\"free energy profile (in units of kT) with 1 sigma errors from posterior sampling\")\n",
    "    for i in range(nbins):\n",
    "        print(f\"{bin_center_i[i]:8.1f} {ci_results['values'][i]:8.1f} {df[i]:8.1f}\")\n",
    "    for i in range(len(pltname)):\n",
    "        plt.figure(i + 1)\n",
    "        plt.legend(fontsize=\"x-small\")\n",
    "        plt.savefig(f\"{pltname[i]}_{fig_suffix}.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
